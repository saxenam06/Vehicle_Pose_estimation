# Vehicle body full SE (3) pose estimation using Surround-view System
In this paper, I provide a Theoretical derivation for Vehicle body SE(3) pose estimation using Images obtained from 4 camera attached around the vehicle by minimizing the Photometric errors. The derivation here is inspired from the recent paper Xiao Liu, Lin Zhang et al. [1] but with a different strategy as explained below, which make this contribution novel.

In the paper of Xiao Liu, Lin Zhang et al. the main idea was to create a consistent surround view image from the well calibrated camera poses. The calibration is normally done offline which may not be sufficient as the camera poses can change when the vehicle experiences other dynamic motions while driving. Therefore, the authors of the paper developed finally a Ground-Camera Model which determines the correct SE(3) poses of the two (out of 4) cameras by minimizing the difference in the Intensity of the image pixels captured by the camera chosen for correction with the Intensity of the image pixels obtained from the ground projections of the two cameras adjacent to the one chosen for correction. The intensity difference is calculated in the image plane of the camera chosen for correction. This process is done individually for each of the two cameras starting with best initial known pose and later optimized until the photometric error reaches minimum. Using the optimum poses for the two cameras results in a consistent surround view image. 

In contrast, I have again derived the Ground-Camera model equations with the SE(3) pose of a frame fixed to the vehicle rigid body as the only variable in optimization. This approach addresses directly the underlying reason of the main source behind the change of the camera poses which is in fact the change of the pose of Vehicle rigid body itself as the 4 cameras are rigidly mounted on the vehicle body. Therefore, I propose to estimate the optimum SE(3) pose of the Vehicle body that minimizes total photometric error for each of the adjacent camera pairs by calculating the difference in Intensity of the image pixels captured by one of the camera (in the pair) with the intensity of the image pixels obtained from the ground projections of the other camera (in the pair). The intensity difference is calculated in the image plane of the former. The projections are performed starting with the best initial known pose and later optimized until the photometric error reaches minimum.

# REFERENCES
1.	Xiao Liu, Lin Zhang et al. Online Camera Pose Optimization for the Surround-view system, 383-391, MM '19: Proceedings of the 27th ACM International Conference on Multimedia
2.	T.D. Barfoot, State Estimation for Robotics. Cambridge University Press, 2017.  

